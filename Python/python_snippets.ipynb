{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Automate CSV writing\n",
    "This automation script will let you easily read and write CSV files. This script uses the Pandas module and below you can find the helpful methods that will be useful to automate your CSV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Automate CSV \n",
    "# pip install pandas\n",
    "import pandas\n",
    "# Read CSV File\n",
    "data = pandas.read_csv(\"test.csv\")\n",
    "# Read CSV Specific Column\n",
    "data = pandas.read_csv(\"test.csv\", usecols=[\"col1\", \"col2\"])\n",
    "# Read CSV Specific Rows\n",
    "data = pandas.read_csv(\"test.csv\", nrows=5)\n",
    "# Read CSV Specific Rows and Columns\n",
    "data = pandas.read_csv(\"test.csv\", usecols=[\"col1\", \"col2\"], nrows=5)\n",
    "# Read CSV File and Convert to JSON\n",
    "data = pandas.read_csv(\"test.csv\").to_json(orient=\"records\")\n",
    "# Write CSV File\n",
    "data = {\"col1\": [\"a\", \"b\", \"c\"], \"col2\": [1, 2, 3]}\n",
    "data = pandas.DataFrame(data)\n",
    "data.to_csv(\"test.csv\", index=False)\n",
    "# Append Column to CSV File\n",
    "data = pandas.read_csv(\"test.csv\")\n",
    "data[\"col3\"] = [\"x\", \"y\", \"z\"]\n",
    "data.to_csv(\"test.csv\", index=False)\n",
    "# Append Row to CSV File\n",
    "data = pandas.read_csv(\"test.csv\")\n",
    "data = data.append({\"col1\": \"d\", \"col2\": 4}, ignore_index=True)\n",
    "data.to_csv(\"test.csv\", index=False)\n",
    "# Drop Column from CSV File\n",
    "data = pandas.read_csv(\"test.csv\")\n",
    "data = data.drop(columns=[\"col3\"])\n",
    "data.to_csv(\"test.csv\", index=False)\n",
    "# Drop Row from CSV File\n",
    "data = pandas.read_csv(\"test.csv\")\n",
    "data = data.drop([2])\n",
    "data.to_csv(\"test.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Increase Photo Definition\n",
    "\n",
    "Now you can upscale your Photos resolution up to 2k, 3k, and 4k easily with this super automation script that uses the Super-Image module. This cool module uses a machine learning algorithm that will upscale the resolution of your photos by filling the missing pixels using different AI models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upscale Your Photos\n",
    "# pip install super-image\n",
    "# pip install pillow\n",
    "from super_image import *\n",
    "from PIL import Image\n",
    "def UpscaleImage(img_file, scale_value):\n",
    "    img = Image.open(img_file)\n",
    "    model = EdsrModel.from_pretrained('eugenesiow/edsr-base', scale=scale_value)\n",
    "    photo = ImageLoader.load_image(img)\n",
    "    upscale = model(photo)\n",
    "    ImageLoader.save_image(upscale,  './upscale.png')\n",
    "UpscaleImage('test.jpg', 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PDF to Audio\n",
    "Create your own Audiobook or convert any pdf to audio format with this killer automation script that uses Text-to-speech and PyPDF2 module. This is handy when you want to convert your whole PDF book or Text to audio format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PDF to Audio\n",
    "# pip install text-to-speech\n",
    "# pip install PyPDF2\n",
    "from text_to_speech import speak\n",
    "from PyPDF2 import PdfFileReader\n",
    "def PDFtoAudio(pdf_path):\n",
    "    text = []\n",
    "    with open(pdf_path, 'rb') as f:\n",
    "        pdf = PdfFileReader(f)\n",
    "        for page in pdf.pages:\n",
    "            text.append(page.extractText())\n",
    "    speak(' '.join(text), 'en', save=True, file='audio_book.mp3')\n",
    "PDFtoAudio('test.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate Text\n",
    "Have you ever wondered if you just write some Topic and Python generates the whole text according to that topic? Well with this awesome automation script you can do that. This script uses the Transformer module that uses the GTP2 module in its background to generate the text by a given topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate Text\n",
    "# pip install transformers\n",
    "from transformers import pipeline\n",
    "def Generate_Text(txt):\n",
    "    gen = pipeline(\"text-generation\", model=\"gpt2\")\n",
    "    output = gen(txt, max_length=100, num_return_sequences=1)\n",
    "    return output[0]['generated_text']\n",
    "print(Generate_Text(\"Science of the future\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Send Marketing Emails\n",
    "Sending marketing Emails to your audience is a common thing for any business. But you can now automate this process using this Python automation script. This fabulous script uses the Mailjet module that allows you to send 200 Emails per day for free. You can get their API easily and automate your Emails."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Send Marketing Emails\n",
    "# pip install mailjet-rest\n",
    "from mailjet_rest import Client\n",
    "SMTP = Client(auth=(\"api_key\", \"api_secret\"))\n",
    "email_data = {\n",
    "    'Messages': [\n",
    "        {\n",
    "            \"From\": {\n",
    "                \"Email\": \"from_email\",\n",
    "                \"Name\": \"from_name\"\n",
    "            },\n",
    "            \"To\": [\n",
    "                {\n",
    "                    \"Email\": \"to_email\",\n",
    "                    \"Name\": \"to_name\"\n",
    "                }\n",
    "            ],\n",
    "            \"Subject\": \"Test Email\",\n",
    "            \"TextPart\": \"Hi there, this is a test email\",\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "mail = SMTP.send.create(data=email_data)\n",
    "print(mail.status_code)\n",
    "print(\"Email sent\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Airtable Extractor\n",
    "Want to extract Airtable data then use this awesome automation script that uses the Airscraper module that will simply take the shareable URL of Airtable then extract the data and store it in the CSV format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Airtable Scraper\n",
    "# pip install airscraper\n",
    "from airscraper import AirScraper\n",
    "def Airtable(urls):\n",
    "    scraper = AirScraper([\"Urls\"])\n",
    "    data = scraper.get_table().text\n",
    "    print(\"Data: \", data)\n",
    "    with open('data.csv','w') as f:\n",
    "        f.write(data)\n",
    "Airtable([\"https://airtable.com/123\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read PDF contents with OCR\n",
    "Python is widely used for analyzing the data but the data need not be in the required format always. In such cases, we convert that format (like PDF or JPG, etc.) to the text format, in order to analyze the data in a better way. Python offers many libraries to do this task. There are several ways of doing this, including using libraries like PyPDF2 in Python. The major disadvantage of using these libraries is the encoding scheme. PDF documents can come in a variety of encodings including UTF-8, ASCII, Unicode, etc. So, converting the PDF to text might result in the loss of data due to the encoding scheme. Let’s see how to read all the contents of a PDF file and store it in a text document using OCR. Firstly, we need to convert the pages of the PDF to images and then, use OCR (Optical Character Recognition) to read the content from the image and store it in a text file. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Part #1 deals with converting the PDF into image files. Each page of the PDF is stored as an image file. The names of the images stored are: PDF page 1 -> page_1.jpg PDF page 2 -> page_2.jpg PDF page 3 -> page_3.jpg …. PDF page n -> page_n.jpg."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Part #2 deals with recognizing text from the image files and storing it into a text file. Here, we process the images and convert it into text. Once we have the text as a string variable, we can do any processing on the text. For example, in many PDFs, when a line is completed, but a particular word cannot be written entirely in the same line, a hyphen (‘-‘) is added, and the word is continued on the next line. For example –\n",
    "```\n",
    "This is some sample text but this parti-\n",
    "cular word could not be written in the same line.\n",
    "```\n",
    "Now for such words, a fundamental pre-processing is done to convert the hyphen and the new line into a full word. After all the pre-processing is done, this text is stored in a separate text file. To get the input PDF files used in the code, click d.pdf. \n",
    "\n",
    "Below is the implementation: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Requires Python 3.6 or higher due to f-strings\n",
    "\n",
    "# install libs needed\n",
    "# pip3 install PIL\n",
    "# pip3 install pytesseract\n",
    "# pip3 install pdf2image\n",
    "# sudo apt-get install tesseract-ocr\n",
    "\n",
    "# Import libraries\n",
    "import platform\n",
    "from tempfile import TemporaryDirectory\n",
    "from pathlib import Path\n",
    "\n",
    "import pytesseract\n",
    "from pdf2image import convert_from_path\n",
    "from PIL import Image\n",
    "\n",
    "if platform.system() == \"Windows\":\n",
    "\t# We may need to do some additional downloading and setup...\n",
    "\t# Windows needs a PyTesseract Download\n",
    "\t# https://github.com/UB-Mannheim/tesseract/wiki/Downloading-Tesseract-OCR-Engine\n",
    "\n",
    "\tpytesseract.pytesseract.tesseract_cmd = (\n",
    "\t\tr\"C:\\Program Files\\Tesseract-OCR\\tesseract.exe\"\n",
    "\t)\n",
    "\n",
    "\t# Windows also needs poppler_exe\n",
    "\tpath_to_poppler_exe = Path(r\"C:\\.....\")\n",
    "\t\n",
    "\t# Put our output files in a sane place...\n",
    "\tout_directory = Path(r\"~\\Desktop\").expanduser()\n",
    "else:\n",
    "\tout_directory = Path(\"~\").expanduser()\t\n",
    "\n",
    "# Path of the Input pdf\n",
    "PDF_file = Path(r\"d.pdf\")\n",
    "\n",
    "# Store all the pages of the PDF in a variable\n",
    "image_file_list = []\n",
    "\n",
    "text_file = out_directory / Path(\"out_text.txt\")\n",
    "\n",
    "def main():\n",
    "\t''' Main execution point of the program'''\n",
    "\twith TemporaryDirectory() as tempdir:\n",
    "\t\t# Create a temporary directory to hold our temporary images.\n",
    "\n",
    "\t\t\"\"\"\n",
    "\t\tPart #1 : Converting PDF to images\n",
    "\t\t\"\"\"\n",
    "\n",
    "\t\tif platform.system() == \"Windows\":\n",
    "\t\t\tpdf_pages = convert_from_path(\n",
    "\t\t\t\tPDF_file, 500, poppler_path=path_to_poppler_exe\n",
    "\t\t\t)\n",
    "\t\telse:\n",
    "\t\t\tpdf_pages = convert_from_path(PDF_file, 500)\n",
    "\t\t# Read in the PDF file at 500 DPI\n",
    "\n",
    "\t\t# Iterate through all the pages stored above\n",
    "\t\tfor page_enumeration, page in enumerate(pdf_pages, start=1):\n",
    "\t\t\t# enumerate() \"counts\" the pages for us.\n",
    "\n",
    "\t\t\t# Create a file name to store the image\n",
    "\t\t\tfilename = f\"{tempdir}\\page_{page_enumeration:03}.jpg\"\n",
    "\n",
    "\t\t\t# Declaring filename for each page of PDF as JPG\n",
    "\t\t\t# For each page, filename will be:\n",
    "\t\t\t# PDF page 1 -> page_001.jpg\n",
    "\t\t\t# PDF page 2 -> page_002.jpg\n",
    "\t\t\t# PDF page 3 -> page_003.jpg\n",
    "\t\t\t# ....\n",
    "\t\t\t# PDF page n -> page_00n.jpg\n",
    "\n",
    "\t\t\t# Save the image of the page in system\n",
    "\t\t\tpage.save(filename, \"JPEG\")\n",
    "\t\t\timage_file_list.append(filename)\n",
    "\n",
    "\t\t\"\"\"\n",
    "\t\tPart #2 - Recognizing text from the images using OCR\n",
    "\t\t\"\"\"\n",
    "\n",
    "\t\twith open(text_file, \"a\") as output_file:\n",
    "\t\t\t# Open the file in append mode so that\n",
    "\t\t\t# All contents of all images are added to the same file\n",
    "\n",
    "\t\t\t# Iterate from 1 to total number of pages\n",
    "\t\t\tfor image_file in image_file_list:\n",
    "\n",
    "\t\t\t\t# Set filename to recognize text from\n",
    "\t\t\t\t# Again, these files will be:\n",
    "\t\t\t\t# page_1.jpg\n",
    "\t\t\t\t# page_2.jpg\n",
    "\t\t\t\t# ....\n",
    "\t\t\t\t# page_n.jpg\n",
    "\n",
    "\t\t\t\t# Recognize the text as string in image using pytesserct\n",
    "\t\t\t\ttext = str(((pytesseract.image_to_string(Image.open(image_file)))))\n",
    "\n",
    "\t\t\t\t# The recognized text is stored in variable text\n",
    "\t\t\t\t# Any string processing may be applied on text\n",
    "\t\t\t\t# Here, basic formatting has been done:\n",
    "\t\t\t\t# In many PDFs, at line ending, if a word can't\n",
    "\t\t\t\t# be written fully, a 'hyphen' is added.\n",
    "\t\t\t\t# The rest of the word is written in the next line\n",
    "\t\t\t\t# Eg: This is a sample text this word here GeeksF-\n",
    "\t\t\t\t# orGeeks is half on first line, remaining on next.\n",
    "\t\t\t\t# To remove this, we replace every '-\\n' to ''.\n",
    "\t\t\t\ttext = text.replace(\"-\\n\", \"\")\n",
    "\n",
    "\t\t\t\t# Finally, write the processed text to the file.\n",
    "\t\t\t\toutput_file.write(text)\n",
    "\n",
    "\t\t\t# At the end of the with .. output_file block\n",
    "\t\t\t# the file is closed after writing all the text.\n",
    "\t\t# At the end of the with .. tempdir block, the\n",
    "\t\t# TemporaryDirectory() we're using gets removed!\t\n",
    "\t# End of main function!\n",
    "\t\n",
    "if __name__ == \"__main__\":\n",
    "\t# We only want to run this if it's directly executed!\n",
    "\tmain()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the above, the pages of the PDF were converted to images. Then the images were read, and the content was written into a text file. \n",
    "\n",
    "Advantages of this method include:\n",
    "\n",
    "- Avoiding text-based conversion because of the encoding scheme resulting in loss of data.\n",
    "- Even handwritten content in PDF can be recognized due to the usage of OCR.\n",
    "- Recognizing only particular pages of the PDF is also possible.\n",
    "- Getting the text as a variable so that any amount of required pre-processing can be done.\n",
    "\n",
    "Disadvantages of this method include:\n",
    "- Disk storage is used to store the images in the local system. Although these images are tiny in size.\n",
    "- Using OCR cannot guarantee 100% accuracy. However, a computer-typed PDF document results in very high accuracy.\n",
    "- Handwritten PDFs are still recognized, but the accuracy depends on various factors like handwriting, page color, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "how to extract price data out of a Zipline Bundle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from zipline.data.bundles.core import load\n",
    "from zipline.data.data_portal import DataPortal\n",
    "from zipline.utils.calendar_utils import get_calendar\n",
    "\n",
    "\n",
    "# Load extensions if you have not already\n",
    "load_extensions(True, [], False, os.environ)\n",
    "\n",
    "# Use your bundle's name\n",
    "bundle_data = load(\"quotemedia\", os.environ, None)\n",
    "\n",
    "\n",
    "as_of_date = pd.Timestamp(\"2024-01-01\")\n",
    "symbols = [\"MSFT\", \"AMZN\", \"NVDA\"]\n",
    "\n",
    "# Get the method that looks up the asset from the Zipline Bundle\n",
    "asset_finder = bundle_data.asset_finder\n",
    "\n",
    "# Get the list of Equity objects by string\n",
    "assets = asset_finder.lookup_symbols(symbols, as_of_date=as_of_date)\n",
    "\n",
    "# Create a DataPortal which handles all the drama of finding the bundle\n",
    "# and stitching together the bocolz files\n",
    "data_portal = DataPortal(\n",
    "    asset_finder=asset_finder,\n",
    "    equity_daily_reader=bundle_data.equity_daily_bar_reader,\n",
    "    trading_calendar=get_calendar(\"NYSE\"),\n",
    "    first_trading_day=pd.Timestamp(\"2000-01-03\"),\n",
    ")\n",
    "\n",
    "# Get the price data. Field can be open, high, low, close, or price.\n",
    "data = data_portal.get_history_window(\n",
    "    assets=assets,\n",
    "    end_dt=pd.Timestamp(\"2023-12-31\"),\n",
    "    bar_count=100,\n",
    "    frequency=\"1d\",\n",
    "    field=\"close\",\n",
    "    data_frequency=\"daily\",\n",
    "    ffill=True\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.14 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.14"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a665b5d41d17b532ea9890333293a1b812fa0b73c9c25c950b3cedf1bebd0438"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
